---
layout: post
title:  "SAT & ACT Analysis"
date:   2020-10-22 10:00:00 +0800
categories: ['Analytics', 'Advance-Visualisation']
excerpt_separator: <!--more-->
---


## Introduction
This is the first project as part of Data Science Immersive Course conducted by General Assembly. This project is to showcase the following skillsets:
- Conceptualization thinking
- Statistical Understanding
- Extraction, Transformation & Loading in python
- Advance Graphing Techniques

## BodeBook
The full codebook can be found [here](https://github.com/KevinSeek/Kevin_Project_Portfolio/tree/master/P001_sat_act_analysis)
<!--more-->

## Scenario

When it comes to college admission exam in the US, ACT (American College Testing) and SAT (Scholastic Aptitude Test) are the 2 default choices taken by Senior High Students. SAT exams used to monopolistic control over the college admission examination but ACT had started to erode SATâ€™s dominance through its effective marketing efforts and more consumer-friendly test format.

To counter the erosion of market dominance, In 2016, The College Board, owner of SAT, redesigned the test in an attempt to revitalize their test participation rate. As part of the data analytics team in College Board, I am tasked to conduct a competitor analysis of SAT and ACT and to recommend to College Board if the revamp has improved participation rate and/or additional marketing effort that can be adopted.

## Problem Statement

- Provide a compeitior analysis, based on the data given by College Board Analystics Team Lead, to advise and recommend where money is best spent to improve SAT participation rates. Extenal Research may be included but should be keep to the minimum.
<br>
- As much as possible, report should enable end-users to interact with any resultant graphs to understand specific aspect of the data. 

## Executive Summary

**Summary of findings**
    
SAT & ACT are the 2 standardized test used by many colleges in the US as part of their admission decision process. Juniors and seniors in high school usually take these tests to demonstrate their readiness for college-level work. Both tests are designed in a different way to measure college readiness and predict future academic success.

After a new format of SAT was released, we would like to see how it perform against its competitor - ACT in term of popularity (measured by participation rate) among high school students as the standardized test for their college admission.

We shall limit the scope of our analysis to states that have SAT participation rate in 2018 that are more than 50%. Other factors may be in play for states which have less 50% participation rate, eg. strong political affiliation to ACT and more data will be necessary which is beyond the scope of this project.



**Key Observations**
- SAT & ACT participation rates in each states are mostly inversely related. An increase in one often mean a decrease in another.

- Negative correlation between participation rate and respective test scores for both SAT & ACT

- Maryland has perform exceptionally worse compared to other states for both SAT & ACT in 2017

- Preference for one test over the other maybe geographically driven - coastal states preferring SAT over ACT.

- We discover states such as Illinois & Colorado have almost a 90% jump in participation rate in 2018 compared to 2017. This may be due to the new format of SAT and various new initiatives such as SAT 'school day' event and educational investment by state.


**Conclusion & Recommendations**

Based on the analysis of the data & additional research, I choose Florida as the next state we can invest in. The reason for choosing the state are as follow:

- Florida is the 3rd largest state in term of the population which means that there are likely to have more students participating in the college admission test.

- As an investment risk mitigation option, we may not be able to replicate the success case of Illinois & Colorado, low SAT to high SAT participation rate. Using Florida, which already have close to 50% participation rate in both SAT and ACT, it is likely to have less 'barrier to entry' for students to switch from ACT to SAT since they may be familiar with the structure of both exams.

- Florida is committed to making a big investment into education, hence it is highly likely to win political favour in expanding into Florida, given that our part of our current initiatives (free online review/classes) can contribute to more students being admitted to college.

Besides, I believe that we should continue & expand current initiatives to other states which still show weakness in SAT participation rate (>50% but below 75%) based on the previous year (2018). This way, we are likely to see improvement in participation rate year-on-year across all states going forward.


**Key Observations**
<ul>
    <li>SAT & ACT participation rates in each states are mostly inversely related. An increase in one often mean a decrease in another.</li><br>
    <li>Negative correlation between participation rate and respective test scores for both SAT & ACT</li><br>
    <li>Year-on-year participation in both states tends to remain the same. Exception for Illinois & Colorado where there are policy changes.</li><br>
    <li>Preference for one test over the other maybe geographically driven - coastal states preferring SAT over ACT.</li>    
</ul>


**Additional observation**
<ul>
    <li>We discover states such as Illinois & Colorado have almost a 90% jump in participation rate in 2018 compared to 2017. This may be due to the new format of SAT and various new initiatives such as SAT 'school day' event and educational investment by state.</li><br>
    <li>States which do not have specific preferred test (states that have more than 50% participation rate in both SAT & ACT) also see a marginal increase in SAT participation rate in 2018.</li>  
</ul>


Based on analysis of the data & additional research, I choose Florida as the next state we can invest in. The reason for choosing the state are as follow:
<ol>
    <li>Florida is the 3rd largest state in term of population which means that there are likely to have more students participating in college admission test.</li><br>
    <li>As an investment risk mitigation option, we may not be able to replicate the success case of Illinois & Colorado, low SAT to high SAT participation rate. Using Florida, which already have close to 50% participation rate in both SAT and ACT, it is likely to have less 'barrier to entry' for students to switch from ACT to SAT since they may be familiar with the structure of both exam.</li><br>
    <li>Florida is committed to make big investment into education, hence it is highly likely to win political favor in expanding into Florida, given that our part of our current initiatives (free online review/classes) can contribute to more students being admitted to college.</li> 
</ol> 

In addition, I believe that we should continue & expand current initiatives to other states which still show weakness in SAT participation rate (>50% but below 75%) based on previous year (2018). This way, we are likely to see improvement in participation rate year-on-year across all states going forward.

## Data Import


```python
# 2017 SAT & ACT Dataset
sat_2017 = pd.read_csv('data/sat_2017.csv')
act_2017 = pd.read_csv('data/act_2017.csv')
```


```python
# First 5 rows of SAT 2017 dataset
print(f'shape of sat_2017: {sat_2017.shape}')
sat_2017.head()
```

    shape of sat_2017: (51, 5)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>State</th>
      <th>Participation</th>
      <th>Evidence-Based Reading and Writing</th>
      <th>Math</th>
      <th>Total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>5%</td>
      <td>593</td>
      <td>572</td>
      <td>1165</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>38%</td>
      <td>547</td>
      <td>533</td>
      <td>1080</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>30%</td>
      <td>563</td>
      <td>553</td>
      <td>1116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>3%</td>
      <td>614</td>
      <td>594</td>
      <td>1208</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>53%</td>
      <td>531</td>
      <td>524</td>
      <td>1055</td>
    </tr>
  </tbody>
</table>
</div>




```python
sat_2017.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 51 entries, 0 to 50
    Data columns (total 5 columns):
     #   Column                              Non-Null Count  Dtype 
    ---  ------                              --------------  ----- 
     0   State                               51 non-null     object
     1   Participation                       51 non-null     object
     2   Evidence-Based Reading and Writing  51 non-null     int64 
     3   Math                                51 non-null     int64 
     4   Total                               51 non-null     int64 
    dtypes: int64(3), object(2)
    memory usage: 2.1+ KB
    


```python
sat_2017.isnull().sum()
```




    State                                 0
    Participation                         0
    Evidence-Based Reading and Writing    0
    Math                                  0
    Total                                 0
    dtype: int64




```python
# First 5 rows of ACT 2017 dataset
print(f'shape of act_2017: {act_2017.shape}')
act_2017.head()
```

    shape of act_2017: (52, 7)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>State</th>
      <th>Participation</th>
      <th>English</th>
      <th>Math</th>
      <th>Reading</th>
      <th>Science</th>
      <th>Composite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>National</td>
      <td>60%</td>
      <td>20.3</td>
      <td>20.7</td>
      <td>21.4</td>
      <td>21.0</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alabama</td>
      <td>100%</td>
      <td>18.9</td>
      <td>18.4</td>
      <td>19.7</td>
      <td>19.4</td>
      <td>19.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Alaska</td>
      <td>65%</td>
      <td>18.7</td>
      <td>19.8</td>
      <td>20.4</td>
      <td>19.9</td>
      <td>19.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arizona</td>
      <td>62%</td>
      <td>18.6</td>
      <td>19.8</td>
      <td>20.1</td>
      <td>19.8</td>
      <td>19.7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Arkansas</td>
      <td>100%</td>
      <td>18.9</td>
      <td>19.0</td>
      <td>19.7</td>
      <td>19.5</td>
      <td>19.4</td>
    </tr>
  </tbody>
</table>
</div>




```python
act_2017.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 52 entries, 0 to 51
    Data columns (total 7 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   State          52 non-null     object 
     1   Participation  52 non-null     object 
     2   English        52 non-null     float64
     3   Math           52 non-null     float64
     4   Reading        52 non-null     float64
     5   Science        52 non-null     float64
     6   Composite      52 non-null     object 
    dtypes: float64(4), object(3)
    memory usage: 3.0+ KB
    


```python
act_2017.isnull().sum()
```




    State            0
    Participation    0
    English          0
    Math             0
    Reading          0
    Science          0
    Composite        0
    dtype: int64




```python
act_2017['Composite'].unique()
```




    array(['21.0', '19.2', '19.8', '19.7', '19.4', '22.8', '20.8', '25.2',
           '24.1', '24.2', '21.4', '19.0', '22.3', '22.6', '21.9', '21.7',
           '20.0', '19.5', '24.3', '23.6', '25.4', '21.5', '18.6', '20.4',
           '20.3', '17.8', '25.5', '23.9', '19.1', '22.0', '21.8', '23.7',
           '24.0', '18.7', '20.7', '23.8', '20.5', '20.2x'], dtype=object)



<span style = "color:Magenta">Comments:</span><br>

SAT
- Has 51 rows and 5 columns. 
- There are 2 string data type and 3 numeric data type.
- For columns of numeric data, the datatype is correct. However, participation is a wrong datatype. It should be numerical rather than string. This is likely due to the '%' sign behind. Remove the '%' symbol and convert it to numeric will help in data wrangling.

ACT
- Has 52 rows and 7 columns.
- There are 3 string data type and 4 numeric data type
- Participation column is of wrong data type and suffers the same the issue as participation in SAT. 
- Composite column is of wrong data type. This is due to a value '20.2x' which causes the entire column to be imputed as string. correctly this will allow the column to transform to numeric type and allow easy data wrangling.

There is no null values and comparing SAT and ACT dataset, ACT has an extra row which shows the National Average. This row will be remove as it is an aggregated row.


## Data Cleaning 2017 Dataset

### Convert column headers into lower case


```python
sat_2017.columns = sat_2017.columns.str.lower()
sat_2017.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>participation</th>
      <th>evidence-based reading and writing</th>
      <th>math</th>
      <th>total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>5%</td>
      <td>593</td>
      <td>572</td>
      <td>1165</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>38%</td>
      <td>547</td>
      <td>533</td>
      <td>1080</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>30%</td>
      <td>563</td>
      <td>553</td>
      <td>1116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>3%</td>
      <td>614</td>
      <td>594</td>
      <td>1208</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>53%</td>
      <td>531</td>
      <td>524</td>
      <td>1055</td>
    </tr>
  </tbody>
</table>
</div>




```python
act_2017.columns = act_2017.columns.str.lower()
act_2017.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>participation</th>
      <th>english</th>
      <th>math</th>
      <th>reading</th>
      <th>science</th>
      <th>composite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>National</td>
      <td>60%</td>
      <td>20.3</td>
      <td>20.7</td>
      <td>21.4</td>
      <td>21.0</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alabama</td>
      <td>100%</td>
      <td>18.9</td>
      <td>18.4</td>
      <td>19.7</td>
      <td>19.4</td>
      <td>19.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Alaska</td>
      <td>65%</td>
      <td>18.7</td>
      <td>19.8</td>
      <td>20.4</td>
      <td>19.9</td>
      <td>19.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arizona</td>
      <td>62%</td>
      <td>18.6</td>
      <td>19.8</td>
      <td>20.1</td>
      <td>19.8</td>
      <td>19.7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Arkansas</td>
      <td>100%</td>
      <td>18.9</td>
      <td>19.0</td>
      <td>19.7</td>
      <td>19.5</td>
      <td>19.4</td>
    </tr>
  </tbody>
</table>
</div>



### Removal of '%' from Participation


```python
# SAT 2017 dataset
sat_2017['participation'] = sat_2017['participation'].apply(str.replace,args=('%',''))
sat_2017['participation'] = sat_2017['participation'].astype(int)
sat_2017.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 51 entries, 0 to 50
    Data columns (total 5 columns):
     #   Column                              Non-Null Count  Dtype 
    ---  ------                              --------------  ----- 
     0   state                               51 non-null     object
     1   participation                       51 non-null     int32 
     2   evidence-based reading and writing  51 non-null     int64 
     3   math                                51 non-null     int64 
     4   total                               51 non-null     int64 
    dtypes: int32(1), int64(3), object(1)
    memory usage: 1.9+ KB
    


```python
# ACT 2017 dataset
act_2017['participation'] = act_2017['participation'].apply(str.replace,args=('%',''))
act_2017['participation'] = act_2017['participation'].astype(int)
act_2017.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 52 entries, 0 to 51
    Data columns (total 7 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   state          52 non-null     object 
     1   participation  52 non-null     int32  
     2   english        52 non-null     float64
     3   math           52 non-null     float64
     4   reading        52 non-null     float64
     5   science        52 non-null     float64
     6   composite      52 non-null     object 
    dtypes: float64(4), int32(1), object(2)
    memory usage: 2.8+ KB
    

### Removing of errors in ACT 2017 Composite Column


```python
act_2017['composite'] = act_2017['composite'].apply(str.replace, args=('x',''))
act_2017['composite'] = act_2017['composite'].astype(float)
# Remove the aggregated row
act_2017 = act_2017[act_2017['state']!='National']
act_2017.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 51 entries, 1 to 51
    Data columns (total 7 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   state          51 non-null     object 
     1   participation  51 non-null     int32  
     2   english        51 non-null     float64
     3   math           51 non-null     float64
     4   reading        51 non-null     float64
     5   science        51 non-null     float64
     6   composite      51 non-null     float64
    dtypes: float64(5), int32(1), object(1)
    memory usage: 3.0+ KB
    

### Describing Data

```python
sat_2017.describe().T
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>participation</th>
      <td>51.0</td>
      <td>39.803922</td>
      <td>35.276632</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>38.0</td>
      <td>66.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>evidence-based reading and writing</th>
      <td>51.0</td>
      <td>569.117647</td>
      <td>45.666901</td>
      <td>482.0</td>
      <td>533.5</td>
      <td>559.0</td>
      <td>613.0</td>
      <td>644.0</td>
    </tr>
    <tr>
      <th>math</th>
      <td>51.0</td>
      <td>547.627451</td>
      <td>84.909119</td>
      <td>52.0</td>
      <td>522.0</td>
      <td>548.0</td>
      <td>599.0</td>
      <td>651.0</td>
    </tr>
    <tr>
      <th>total</th>
      <td>51.0</td>
      <td>1126.098039</td>
      <td>92.494812</td>
      <td>950.0</td>
      <td>1055.5</td>
      <td>1107.0</td>
      <td>1212.0</td>
      <td>1295.0</td>
    </tr>
  </tbody>
</table>
</div>


```python
sat_2017[sat_2017['participation']==2]
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>participation</th>
      <th>evidence-based reading and writing</th>
      <th>math</th>
      <th>total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15</th>
      <td>Iowa</td>
      <td>2</td>
      <td>641</td>
      <td>635</td>
      <td>1275</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Mississippi</td>
      <td>2</td>
      <td>634</td>
      <td>607</td>
      <td>1242</td>
    </tr>
    <tr>
      <th>34</th>
      <td>North Dakota</td>
      <td>2</td>
      <td>635</td>
      <td>621</td>
      <td>1256</td>
    </tr>
  </tbody>
</table>
</div>

```python
sat_2017[sat_2017['math']==52]
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>participation</th>
      <th>evidence-based reading and writing</th>
      <th>math</th>
      <th>total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20</th>
      <td>Maryland</td>
      <td>69</td>
      <td>536</td>
      <td>52</td>
      <td>1060</td>
    </tr>
  </tbody>
</table>
</div>



<span style = "color:Magenta">Comments:</span><br>

SAT
- 800 points per section with a max score of 1600
- Not scaled by test population. Actual Score is used hence possible to see actual Min & Max score.


SAT 2017
1. Participation rate has a mean at 39% while min is at 2% and max at 100% suggest high variance across states. 3 states = Lowa, Mississippi & North Dakota have the lowest participation rate at 2%.
2. Both Writing & Math have a mean of around 540++ and max of around 640+. However, the min for math is 52. Upon further checks, Maryland is the outlier that resulted in a math score of 52.


```python
act_2017.describe().T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>participation</th>
      <td>51.0</td>
      <td>65.254902</td>
      <td>32.140842</td>
      <td>8.0</td>
      <td>31.00</td>
      <td>69.0</td>
      <td>100.00</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>english</th>
      <td>51.0</td>
      <td>20.931373</td>
      <td>2.353677</td>
      <td>16.3</td>
      <td>19.00</td>
      <td>20.7</td>
      <td>23.30</td>
      <td>25.5</td>
    </tr>
    <tr>
      <th>math</th>
      <td>51.0</td>
      <td>21.182353</td>
      <td>1.981989</td>
      <td>18.0</td>
      <td>19.40</td>
      <td>20.9</td>
      <td>23.10</td>
      <td>25.3</td>
    </tr>
    <tr>
      <th>reading</th>
      <td>51.0</td>
      <td>22.013725</td>
      <td>2.067271</td>
      <td>18.1</td>
      <td>20.45</td>
      <td>21.8</td>
      <td>24.15</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>science</th>
      <td>51.0</td>
      <td>21.041176</td>
      <td>3.182463</td>
      <td>2.3</td>
      <td>19.90</td>
      <td>21.3</td>
      <td>22.75</td>
      <td>24.9</td>
    </tr>
    <tr>
      <th>composite</th>
      <td>51.0</td>
      <td>21.519608</td>
      <td>2.020695</td>
      <td>17.8</td>
      <td>19.80</td>
      <td>21.4</td>
      <td>23.60</td>
      <td>25.5</td>
    </tr>
  </tbody>
</table>
</div>




```python
act_2017[act_2017['participation']==8]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>participation</th>
      <th>english</th>
      <th>math</th>
      <th>reading</th>
      <th>science</th>
      <th>composite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20</th>
      <td>Maine</td>
      <td>8</td>
      <td>24.2</td>
      <td>24.0</td>
      <td>24.8</td>
      <td>23.7</td>
      <td>24.3</td>
    </tr>
  </tbody>
</table>
</div>




```python
act_2017[act_2017['science']==2.3]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>participation</th>
      <th>english</th>
      <th>math</th>
      <th>reading</th>
      <th>science</th>
      <th>composite</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>21</th>
      <td>Maryland</td>
      <td>28</td>
      <td>23.3</td>
      <td>23.1</td>
      <td>24.2</td>
      <td>2.3</td>
      <td>23.6</td>
    </tr>
  </tbody>
</table>
</div>



<span style = "color:Magenta">Comments:</span><br>

ACT
- 36 points per section with a max score of 36 (Composite is an avg of all sections)
- Scaling by test population. Not possible to see the actual min and max score


ACT 2017
1. Because of the scaling, the mean for each sections are around 20+ range. However, even after scaling, science min score is at 2.3. Again, Maryland is the outlier that resulted in the lowest score for ACT,science.
2. Participation Rate mean is around 65% suggesting a higher part rate compared to SAT. However, Maine has the lowest participation rate at 8%.

### Renaming Columns

By renaming the columns to be more expressive can allow us qucikly to tell the difference between SAT & ACT columns and by using right abbreviation, it reduces the efforts to transform the data yet retaining the meaning behind the columns.


```python
# Create a mapping dictionary for both SAT & ACT
# Revert prefixed states to without prefixs
header_dict =  {'participation': 'part_rate',
                'evidence-based reading and writing': 'ebrw',
                'math': 'math',
                'total': 'total',
                'english': 'eng',
                'Reading': 'read',
                'science': 'sci',
                'composite':'total'}

# Add sat prefix to SAT dataset
sat_2017.rename(header_dict,axis=1, inplace=True)
sat_2017 = sat_2017.add_prefix('sat_')
sat_2017.rename({'sat_state':'state'}, axis=1, inplace=True)
sat_2017.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate</th>
      <th>sat_ebrw</th>
      <th>sat_math</th>
      <th>sat_total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>5</td>
      <td>593</td>
      <td>572</td>
      <td>1165</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>38</td>
      <td>547</td>
      <td>533</td>
      <td>1080</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>30</td>
      <td>563</td>
      <td>553</td>
      <td>1116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>3</td>
      <td>614</td>
      <td>594</td>
      <td>1208</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>53</td>
      <td>531</td>
      <td>524</td>
      <td>1055</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Add act prefix to ACT dataset
act_2017.rename(header_dict,axis=1, inplace=True)
act_2017 = act_2017.add_prefix('act_')
act_2017.rename({'act_state':'state'}, axis=1, inplace=True)
act_2017.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>act_part_rate</th>
      <th>act_eng</th>
      <th>act_math</th>
      <th>act_reading</th>
      <th>act_sci</th>
      <th>act_total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Alabama</td>
      <td>100</td>
      <td>18.9</td>
      <td>18.4</td>
      <td>19.7</td>
      <td>19.4</td>
      <td>19.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Alaska</td>
      <td>65</td>
      <td>18.7</td>
      <td>19.8</td>
      <td>20.4</td>
      <td>19.9</td>
      <td>19.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arizona</td>
      <td>62</td>
      <td>18.6</td>
      <td>19.8</td>
      <td>20.1</td>
      <td>19.8</td>
      <td>19.7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Arkansas</td>
      <td>100</td>
      <td>18.9</td>
      <td>19.0</td>
      <td>19.7</td>
      <td>19.5</td>
      <td>19.4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>California</td>
      <td>31</td>
      <td>22.5</td>
      <td>22.7</td>
      <td>23.1</td>
      <td>22.2</td>
      <td>22.8</td>
    </tr>
  </tbody>
</table>
</div>



### Merging DataFrame


```python
# Print the shape of act_2017 & sat_2017
print(f'shape of act_2017 dataframe: {act_2017.shape}')
print(f'shape of sat_2017 dataframe: {sat_2017.shape}')
print('')
print('*' * 60)
print('')
# merge dataframe - common column is state
test_2017 = pd.merge(sat_2017, act_2017, how='outer', on='state')
print(f'shape of test_2017 dataframe: {test_2017.shape}')
```

    shape of act_2017 dataframe: (51, 7)
    shape of sat_2017 dataframe: (51, 5)
    
    ************************************************************
    
    shape of test_2017 dataframe: (51, 11)
    

<span style = "color:Magenta">Comments:</span><br>
Given that the states in both dataframes are the same Joining by the key column = 'state' using either 'inner', 'outer', 'left', 'right' will produce the same result. However, to future proof the codes, using 'outer' will be more comprehensive to capture/preserve any new state addition from both dataframes. 


```python
test_2017.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate</th>
      <th>sat_ebrw</th>
      <th>sat_math</th>
      <th>sat_total</th>
      <th>act_part_rate</th>
      <th>act_eng</th>
      <th>act_math</th>
      <th>act_reading</th>
      <th>act_sci</th>
      <th>act_total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>5</td>
      <td>593</td>
      <td>572</td>
      <td>1165</td>
      <td>100</td>
      <td>18.9</td>
      <td>18.4</td>
      <td>19.7</td>
      <td>19.4</td>
      <td>19.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>38</td>
      <td>547</td>
      <td>533</td>
      <td>1080</td>
      <td>65</td>
      <td>18.7</td>
      <td>19.8</td>
      <td>20.4</td>
      <td>19.9</td>
      <td>19.8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>30</td>
      <td>563</td>
      <td>553</td>
      <td>1116</td>
      <td>62</td>
      <td>18.6</td>
      <td>19.8</td>
      <td>20.1</td>
      <td>19.8</td>
      <td>19.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>3</td>
      <td>614</td>
      <td>594</td>
      <td>1208</td>
      <td>100</td>
      <td>18.9</td>
      <td>19.0</td>
      <td>19.7</td>
      <td>19.5</td>
      <td>19.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>53</td>
      <td>531</td>
      <td>524</td>
      <td>1055</td>
      <td>31</td>
      <td>22.5</td>
      <td>22.7</td>
      <td>23.1</td>
      <td>22.2</td>
      <td>22.8</td>
    </tr>
  </tbody>
</table>
</div>



### Save 2017 Merged data


```python
test_2017.to_csv('data/combined_2017.csv')
```

## Data Cleaning 2018 Dataset

Cleaning of 2018 dataset is the same as 2017. Please refer to the notebook for the full [code](#codebook).


## Combine 2 test datasets


```python
# Merge 2017 & 2018 data set
test_data = pd.merge(test_2017,test_2018, how='outer', on='state', suffixes=['_2017', '_2018'])

# Check Test dataset
print(f'Shape of test dataframe: {test_data.shape}')
test_data.head()
```

    Shape of test dataframe: (51, 21)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate_2017</th>
      <th>sat_ebrw_2017</th>
      <th>sat_math_2017</th>
      <th>sat_total_2017</th>
      <th>act_part_rate_2017</th>
      <th>act_eng_2017</th>
      <th>act_math_2017</th>
      <th>act_reading_2017</th>
      <th>act_sci_2017</th>
      <th>...</th>
      <th>sat_part_rate_2018</th>
      <th>sat_ebrw_2018</th>
      <th>sat_math_2018</th>
      <th>sat_total_2018</th>
      <th>act_part_rate_2018</th>
      <th>act_total_2018</th>
      <th>act_eng_2018</th>
      <th>act_math_2018</th>
      <th>act_reading_2018</th>
      <th>act_sci_2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>5</td>
      <td>593</td>
      <td>572</td>
      <td>1165</td>
      <td>100</td>
      <td>18.9</td>
      <td>18.4</td>
      <td>19.7</td>
      <td>19.4</td>
      <td>...</td>
      <td>6</td>
      <td>595</td>
      <td>571</td>
      <td>1166</td>
      <td>100</td>
      <td>19.1</td>
      <td>18.9</td>
      <td>18.3</td>
      <td>19.6</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>38</td>
      <td>547</td>
      <td>533</td>
      <td>1080</td>
      <td>65</td>
      <td>18.7</td>
      <td>19.8</td>
      <td>20.4</td>
      <td>19.9</td>
      <td>...</td>
      <td>43</td>
      <td>562</td>
      <td>544</td>
      <td>1106</td>
      <td>33</td>
      <td>20.8</td>
      <td>19.8</td>
      <td>20.6</td>
      <td>21.6</td>
      <td>20.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>30</td>
      <td>563</td>
      <td>553</td>
      <td>1116</td>
      <td>62</td>
      <td>18.6</td>
      <td>19.8</td>
      <td>20.1</td>
      <td>19.8</td>
      <td>...</td>
      <td>29</td>
      <td>577</td>
      <td>572</td>
      <td>1149</td>
      <td>66</td>
      <td>19.2</td>
      <td>18.2</td>
      <td>19.4</td>
      <td>19.5</td>
      <td>19.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>3</td>
      <td>614</td>
      <td>594</td>
      <td>1208</td>
      <td>100</td>
      <td>18.9</td>
      <td>19.0</td>
      <td>19.7</td>
      <td>19.5</td>
      <td>...</td>
      <td>5</td>
      <td>592</td>
      <td>576</td>
      <td>1169</td>
      <td>100</td>
      <td>19.4</td>
      <td>19.1</td>
      <td>18.9</td>
      <td>19.7</td>
      <td>19.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>53</td>
      <td>531</td>
      <td>524</td>
      <td>1055</td>
      <td>31</td>
      <td>22.5</td>
      <td>22.7</td>
      <td>23.1</td>
      <td>22.2</td>
      <td>...</td>
      <td>60</td>
      <td>540</td>
      <td>536</td>
      <td>1076</td>
      <td>27</td>
      <td>22.7</td>
      <td>22.5</td>
      <td>22.5</td>
      <td>23.0</td>
      <td>22.1</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 21 columns</p>
</div>




```python
# Save combined data as a csv
test_data.to_csv('data/final.csv')
```

<span style = "color:Magenta">Comments:</span><br>
By combining the 2 datasets, we will have a single dataframe to do our analysis on and easier to create graphs for analysis

## Visualizing Data
### Correlation Heatmap of all numeric features


```python
# Creating a mask to make the heatmap more visible
mask = np.zeros_like(test_data.corr())
mask[np.triu_indices_from(mask)] = True

# Setting up the plot
figure, ax = plt.subplots(1,1, figsize=(20,10))
sns.heatmap(test_data.corr(), annot=True, mask=mask)
plt.xticks(rotation=45)
plt.suptitle('Correlation Heatmap of Numeric Features', fontsize=24);
```
![Correlation Heatmap of numeric features](/images/portfolio/p001_sat_act_analysis/CorrelationHeatMap.png)

<span style = "color:Magenta">Comments:</span><br>
From the correlation heat map, we can see that the participation rate has a negative linear relationship with the test results (Negative Correlation); This is inline with what we expected that students will be less likely to participate should the previous year average test result are high. As the test result will determine if a student will receive scholarship/admission to their desired college. They would prefer a test where the average score are lower, implicitly easier to beat. 

Because of this mentality, we can see that the rest of the correlation of other numeric features are inline with this direction.


```python
test_data[['sat_part_rate_2017','sat_part_rate_2018','act_part_rate_2017', 'act_part_rate_2018']].describe().T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sat_part_rate_2017</th>
      <td>51.0</td>
      <td>39.803922</td>
      <td>35.276632</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>38.0</td>
      <td>66.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>sat_part_rate_2018</th>
      <td>51.0</td>
      <td>45.745098</td>
      <td>37.314256</td>
      <td>2.0</td>
      <td>4.5</td>
      <td>52.0</td>
      <td>77.5</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>act_part_rate_2017</th>
      <td>51.0</td>
      <td>65.254902</td>
      <td>32.140842</td>
      <td>8.0</td>
      <td>31.0</td>
      <td>69.0</td>
      <td>100.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>act_part_rate_2018</th>
      <td>51.0</td>
      <td>61.647059</td>
      <td>34.080976</td>
      <td>7.0</td>
      <td>28.5</td>
      <td>66.0</td>
      <td>100.0</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
</div>



### Test Participation Rate Year on Year - Histogram


```python
# Create subplots containers
fig = make_subplots(rows=2, cols=2, subplot_titles=('SAT', 'ACT'), shared_xaxes=True, vertical_spacing=0.05, horizontal_spacing=0.05)

# Add traces
fig.add_trace(go.Histogram(x=test_data['sat_part_rate_2017'], xbins = dict(start=0, end=100,size=10),name='SAT Part_Rate 2017',marker_color='lightpink'), row=1, col=1)
fig.add_trace(go.Histogram(x=test_data['act_part_rate_2017'], xbins = dict(start=0, end=100,size=10),name='ACT Part_Rate 2017',marker_color='lightblue'), row=1, col=2)
fig.add_trace(go.Histogram(x=test_data['sat_part_rate_2018'], xbins = dict(start=0, end=100,size=10),name='SAT Part_Rate 2018',marker_color='lightpink'), row=2, col=1)
fig.add_trace(go.Histogram(x=test_data['act_part_rate_2018'], xbins = dict(start=0, end=100,size=10),name='ACT Part_Rate 2018',marker_color='lightblue'), row=2, col=2)

# Add vertical lines
fig.add_shape(type='line', xref='x1', yref='y1', x0=38, y0=0, x1=38, y1=20, line_dash ='dashdot', line_color='red', name='median')
fig.add_shape(type='line', xref='x1', yref='y1', x0=39, y0=0, x1=39, y1=20, line_dash ='dashdot', line_color='black', name='mean')

fig.add_shape(type='line', xref='x2', yref='y2', x0=69, y0=0, x1=69, y1=20, line_dash ='dashdot', line_color='red', name='median')
fig.add_shape(type='line', xref='x2', yref='y2', x0=65, y0=0, x1=65, y1=20, line_dash ='dashdot', line_color='black', name='mean')

fig.add_shape(type='line', xref='x3', yref='y3', x0=52, y0=0, x1=52, y1=20, line_dash ='dashdot', line_color='red', name='median')
fig.add_shape(type='line', xref='x3', yref='y3', x0=46, y0=0, x1=46, y1=20, line_dash ='dashdot', line_color='black', name='mean')

fig.add_shape(type='line', xref='x4', yref='y4', x0=66, y0=0, x1=66, y1=20, line_dash ='dashdot', line_color='red', name='median')
fig.add_shape(type='line', xref='x4', yref='y4', x0=62, y0=0, x1=62, y1=20, line_dash ='dashdot', line_color='black', name='mean')

# Formatting
## Setup x-axes properties
fig.update_xaxes(title_text='Participation Rate', row=2,col=1)
fig.update_xaxes(title_text='Participation Rate', row=2,col=2)

## Setup y-axes properties
fig.update_yaxes(title_text='2017 Part_rate Freq', row=1,col=1)
fig.update_yaxes(title_text='2018 Part_rate Freq', row=2,col=1)

## Update Canvas
fig.update_layout(width=1200, height=600, title_text='Test Participation Rate Year on Year')

# Show Canvas
fig.show()
```

{% include portfolio/p001_sat_act_analysis/test_part_rate_yoy.html %}

<span style = "color:Magenta">Comments:</span><br>
The red line indicates the Median  
The black line indicates the Mean

Based on the shape of the charts, mean and median lines:

- More people are participating in SAT Test in 2018 compared to 2017
- Less people are participating in ACT Test in 2018 compared to 2017

### Test Participation Rate - Swarm/Box plot


```python
plot_swarmbox(test_data,['sat_part_rate_2017', 'sat_part_rate_2018',\
                       'act_part_rate_2017', 'act_part_rate_2018'],\
            'SAT Part Rate (%)','Part_rate in %', 'Test/year')
```


![Test Participation Swarm Box Plot](/images/portfolio/p001_sat_act_analysis/SwarmBox_TestPartRate.png)


<span style = "color:Magenta">Comments:</span><br>

SAT
- Median of participation rate increase from 2017 to 2018
- More school in each states are increasing their participation in SAT

ACT
- Median of participation decrease marginally from 2017 to 2018
- More schools in each states are reducing their participation in ACT
- ACT has higher minimum participation rate compared to SAT in both 2017 & 2017


### Test Participation Rate Year on Year - Regplot


```python
fig, ax = plt.subplots(2,2, figsize=(15,12))

subplot_regplot('sat_part_rate_2017', 'sat_part_rate_2018', test_data, ax[0,0], 'Regplot of SAT Part Rate 2017 vs 2018')
subplot_regplot('act_part_rate_2017', 'act_part_rate_2018', test_data, ax[0,1], 'Regplot of ACT Part Rate 2017 vs 2018')
subplot_regplot('sat_part_rate_2017', 'act_part_rate_2017', test_data, ax[1,0], 'Regplot of SAT vs ACT Part Rate (2017)')
subplot_regplot('sat_part_rate_2018', 'act_part_rate_2018', test_data, ax[1,1], 'Regplot of SAT vs ACT Part Rate (2018)')
```


![Regplot of Test Part Rate YoY](/images/portfolio/p001_sat_act_analysis/Regplot_TestPartRate.png)



```python
test_data[['state','sat_part_rate_2017', 'sat_part_rate_2018']][(test_data['sat_part_rate_2017']< 25) & (test_data['sat_part_rate_2018']>80)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate_2017</th>
      <th>sat_part_rate_2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>Colorado</td>
      <td>11</td>
      <td>100</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Illinois</td>
      <td>9</td>
      <td>99</td>
    </tr>
  </tbody>
</table>
</div>




```python
test_data[['state','sat_part_rate_2017', 'sat_part_rate_2018']][(test_data['sat_part_rate_2017']> 80) & (test_data['sat_part_rate_2018']< 60)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate_2017</th>
      <th>sat_part_rate_2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>Florida</td>
      <td>83</td>
      <td>56</td>
    </tr>
  </tbody>
</table>
</div>




```python
test_data[['state','act_part_rate_2017', 'act_part_rate_2018']][(test_data['act_part_rate_2017']< 85) & (test_data['act_part_rate_2018']> 95)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>act_part_rate_2017</th>
      <th>act_part_rate_2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>27</th>
      <td>Nebraska</td>
      <td>84</td>
      <td>100</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Ohio</td>
      <td>75</td>
      <td>100</td>
    </tr>
  </tbody>
</table>
</div>




```python
test_data[['state','act_part_rate_2017', 'act_part_rate_2018']][(test_data['act_part_rate_2017']> 60) & (test_data['act_part_rate_2018']< 50)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>act_part_rate_2017</th>
      <th>act_part_rate_2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>65</td>
      <td>33</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Colorado</td>
      <td>100</td>
      <td>30</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Illinois</td>
      <td>93</td>
      <td>43</td>
    </tr>
  </tbody>
</table>
</div>



<span style = "color:Magenta">Comments:</span><br>

<ul>
    <li>SAT</li>
    <ul>
        <li>States have continued to maintained their participation rate year-on-year.</li>
        <li>2 states, Illinois (89%) & Colorado (90%), which have low participation rate in 2017 have a large jump in participation rate in 2018 </li>
        <li>Florida shows a drop in participation in 2018 - from 83% to 56%.</li>
    </ul>
    <br><br>
    <li>ACT</li>
    <ul>
        <li>States have continued to maintained their participation rate year-on-year</li>
        <li>Rate of participation year-on-year have improved for 2 states: -Nebraska (84% -> 100%) & Ohio ( 75% -> 100%)</li>
        <li>Rate of participation year-on-year have dropped for 3 states:
- Alaska (66% -> 33%), Colorado( 100% -> 30%), Illinois (93% -> 43%)</li>
    </ul>
    <br><br>
    <li>SAT vs ACT 2017</li>
    <ul>
        <li>General down trend indicating inverse relationship between ACT participation rate and SAT participation.</li>
        <li>3 states namely Florida, Gerogia and Hawaii, have a more balance participation between ACT & SAT. This may be due to students generally being more competitive and want to have an edge over their peers.</li>
    </ul>
    <br><br>
    <li>SAT vs ACT 2018</li>
    <ul>
        <li>General down trend indicating inverse relationship between ACT participation rate and SAT participation.</li>
        <li>More states are trending to lower right of charts in 2018 may indicate renew interest in partaking SAT compared to ACT as the college admission exam.</li>
    </ul>
</ul>
## Descriptive & Inferential Statistics

### SAT Part Rate 2017/2018


```python
# Create a new df to house a melted Total score & Part-Rate across year
sat_TS = melter(test_data, 'sat_total_2017', test_data,'sat_total_2018', 'sat_total', 'sat_total_score')
sat_PR = melter(test_data, 'sat_part_rate_2017', test_data,'sat_part_rate_2018', 'sat_PR', 'sat_part_rate')

# Merge dataframe together
sat_TS_PR = pd.merge(sat_PR,sat_TS, how='outer', left_index=True, right_index=True)

# Create a df to house SAT Part Rate stats by year
sat_PR_stats = test_data[['sat_part_rate_2017', 'sat_part_rate_2018']].describe()
```


```python
gridplot(test_data, 'sat_part_rate_2017', 'sat_part_rate_2018', sat_TS_PR, 'sat_part_rate', 'sat_total_score', 'sat_PR', (15,12), 'SAT Participation Rate 2017/18', \
         'Distribution of SAT part_rate across state', 'Swarm/Box plot of SAT part_rate', 'Scatterplot of SAT Part Rate vs SAT Total Score by year')
```


![SAT part_rate 2017/2018](/images/portfolio/p001_sat_act_analysis/SAT_PartRate_plot.png)


<span style = "color:Magenta">Comments:</span><br>

<ol>
    <li>The central tendency did not fully explain the SAT Participation Rate for year 2017 & 2018.</li>
    <li>The 2017 Mean of ~ 0.4 & 2018 Mean of ~ 0.46 do not fully explained the 'dual peaks' in the Probability Density f(x)</li>
    <li>The Inter-quartile Range also cannot fully explain the 'spread' of the data. The median and the upper quartile is affected by another cluster around the 60% level.</li>
    <li>The bottom cluster formed could be due to having high avg SAT score - deterred students from participating if they do not believe they could score more than the state's avg.</li>
    <li>More sampling are required to find the true mean participation rate in both years.</li>
</ol>

### ACT Part Rate 2017/2018


```python
# Create a new df to house a melted Total score & Part-Rate across year
act_TS = melter(test_data, 'act_total_2017', test_data,'act_total_2018', 'act_total', 'act_total_score')
act_PR = melter(test_data, 'act_part_rate_2017', test_data,'act_part_rate_2018', 'act_PR', 'act_part_rate')

# Merge dataframe together
act_TS_PR = pd.merge(act_PR, act_TS, how='outer', left_index=True, right_index=True)

# Create a df to house SAT Part Rate stats by year
act_PR_stats = test_data[['act_part_rate_2017', 'act_part_rate_2018']].describe()
```


```python
gridplot(test_data, 'act_part_rate_2017', 'act_part_rate_2018', act_TS_PR, 'act_part_rate', 'act_total_score', 'act_PR', (15,12), 'ACT Participation Rate 2017/18', \
         'Distribution of ACT part_rate across state', 'Swarm/Box plot of ACT part_rate', 'Scatterplot of ACT Part Rate vs ACT Total Score by year')
```


![ACT part_rate 2017/2018](/images/portfolio/p001_sat_act_analysis/ACT_PartRate_plot.png)


<span style = "color:Magenta">Comments:</span><br>

<ol>
    <li>The central tendency did not fully explain the ACT Participation Rate for year 2017 & 2018.</li>
    <li>The 2017 Mean of ~ 0.65 & 2018 Mean of ~ 0.61 do not fully explained the 'dual peaks' in the Probability Density f(x). Also, the swarmplot also show 2 clustering around 30% & 100% participation rate for both years.</li>
    <li>The Inter-quartile Range also cannot fully explain the 'spread' of the data. The median is affected by the 2 clusters at 30% & 100%.</li>
    <li>The clustering formed could be due to having high avg state ACT score deterring students from participating if they do not believe they could score more than the state's avg.</li>
    <li>More sampling are required to find the true mean participation rate in both years.</li>
</ol>


```python
# Plotting of charts
fig, ax = plt.subplots(3,1, figsize=(15,12))

sns.distplot(test_data['act_part_rate_2017'],bins=np.arange(0,100,5),kde=True, color='blue', ax=ax[0])
sns.distplot(test_data['act_part_rate_2018'],bins=np.arange(0,100,5),kde=True, color='red', ax=ax[0])

sns.distplot(test_data['act_math_2017'],bins=np.arange(10,30,0.2),kde=True, color='blue', ax=ax[1])
sns.distplot(test_data['act_math_2018'],bins=np.arange(10,30,0.2),kde=True, color='red', ax=ax[1])

sns.distplot(test_data['act_reading_2017'],bins=np.arange(10,30,0.2),kde=True, color='blue', ax=ax[2])
sns.distplot(test_data['act_reading_2018'],bins=np.arange(10,30,0.2),kde=True, color='red', ax=ax[2])

ax[0].set_title('Distplot of ACT Part Rate by year')
ax[0].legend(['act_part_rate_2017', 'act_part_rate_2018'])
ax[0].set_xlabel('')

ax[1].set_title('Distplot of ACT Math')
ax[1].legend(['act_math_2017', 'act_math_2018'])
ax[1].set_xlabel('')

ax[2].set_title('Distplot of ACT Reading by year')
ax[2].legend(['act_reading_2017', 'act_reading_2018'])
ax[2].set_xlabel('');
```


![ACT Breakdown plot](/images/portfolio/p001_sat_act_analysis/ACT_Breakdown_Plot.png)


### Distributions in the data

In this dataset: 
- Each data represents a sample from a pouplation - the total nationwide high school senior that took SAT and/or ACT in a particular year.
- The number of sample for each test - 51 represents the total number of states. 
- In addition, we do not know the sample size for each state - the sample size varies by the number of participants in each state, and therefore each sample's mean is calculated against different totals. 

From the visualisation done, none of the variables follow a normal distribution. This is due to a few reasons: 
- The sampling done from the population is not random, as it is influenced by outside factors such as state legislation, contracts with schools, etc.
- The size fo the sample as mentioned is not constant. participation rates in each state are derived from total number of seniors taking SAT and/or ACT in that year. Therefore result in high variance in sample size.
- The sample size of 51 is too low for providing a good representation of the population.

Although per Central Limit Theorem, the minimum threshold is 30 to assume that data we sample from a population will be normally distributed. However, it really depends on the data that we have and clearly in our dataset, even with 51 data points, exceeding the minimum threshold, we do not see our data being normally distributed.

For the normality assumption to hold true:
- The sampling has to be random (i.e. no arbritary constraints imposed on the sampling process such as legislation)
- The number of samples has to be big enough.
- The sample size ideally should be constant.

### Question: 
**Is it appropriate to compare SAT and ACT math scores  - can we say students with higher SAT math score is better than those with lower ACT math score, or vice versa?**

The scoring in both math are of different scoring criteria and are also scored on a different scale. Even if we conduct a hypothesis using: <br>
    <span style = 'color: blue'>H_null: SAT Math Score = ACT Math Score</span> <br>
    <span style = 'color: blue'>H_alt: SAT Math Score <> ACT Math Score</span> <br>
We are unable to make the comparision as they are very different tests.

### Question:
**Based upon your observations, choose three states that demonstrate interesting trends in their SAT and/or ACT participation rates**

Summary Statistic of SAT Total Score & ACT Composite Score


```python
test_data[['sat_total_2017', 'act_total_2017', 'sat_total_2018', 'act_total_2018']].describe().T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sat_total_2017</th>
      <td>51.0</td>
      <td>1126.098039</td>
      <td>92.494812</td>
      <td>950.0</td>
      <td>1055.50</td>
      <td>1107.0</td>
      <td>1212.00</td>
      <td>1295.0</td>
    </tr>
    <tr>
      <th>act_total_2017</th>
      <td>51.0</td>
      <td>21.519608</td>
      <td>2.020695</td>
      <td>17.8</td>
      <td>19.80</td>
      <td>21.4</td>
      <td>23.60</td>
      <td>25.5</td>
    </tr>
    <tr>
      <th>sat_total_2018</th>
      <td>51.0</td>
      <td>1120.019608</td>
      <td>94.155083</td>
      <td>977.0</td>
      <td>1057.50</td>
      <td>1098.0</td>
      <td>1204.00</td>
      <td>1298.0</td>
    </tr>
    <tr>
      <th>act_total_2018</th>
      <td>51.0</td>
      <td>21.486275</td>
      <td>2.106278</td>
      <td>17.7</td>
      <td>19.95</td>
      <td>21.3</td>
      <td>23.55</td>
      <td>25.6</td>
    </tr>
  </tbody>
</table>
</div>



**States with >50% participation rate in both tests in either year - Georgia**


```python
states_of_interests = test_data['state'].isin(['Florida','Georgia', 'Hawaii'])
col_of_interest = ['state', 'sat_part_rate_2017', 'sat_total_2017', \
                   'act_part_rate_2017', 'act_total_2017',\
                  'sat_part_rate_2018', 'sat_total_2018', \
                  'act_part_rate_2018', 'act_total_2018']
test_data.loc[states_of_interests, col_of_interest]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate_2017</th>
      <th>sat_total_2017</th>
      <th>act_part_rate_2017</th>
      <th>act_total_2017</th>
      <th>sat_part_rate_2018</th>
      <th>sat_total_2018</th>
      <th>act_part_rate_2018</th>
      <th>act_total_2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>Florida</td>
      <td>83</td>
      <td>1017</td>
      <td>73</td>
      <td>19.8</td>
      <td>56</td>
      <td>1099</td>
      <td>66</td>
      <td>19.9</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Georgia</td>
      <td>61</td>
      <td>1050</td>
      <td>55</td>
      <td>21.4</td>
      <td>70</td>
      <td>1064</td>
      <td>53</td>
      <td>21.4</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Hawaii</td>
      <td>55</td>
      <td>1085</td>
      <td>90</td>
      <td>19.0</td>
      <td>56</td>
      <td>1010</td>
      <td>89</td>
      <td>18.9</td>
    </tr>
  </tbody>
</table>
</div>



**Large Jump in participation rate in Illinois & Colorado**


```python
# Create a subset dataframe tt for further manipulation
tt = test_data.loc[:,['state', 'sat_part_rate_2017', 'sat_total_2017',\
           'sat_part_rate_2018', 'sat_total_2018']]
tt['sat_part_rate_change'] = test_data['sat_part_rate_2018'] - test_data['sat_part_rate_2017']
tt['act_part_rate_change'] = test_data['act_part_rate_2018'] - test_data['act_part_rate_2017']
tt.sort_values('sat_part_rate_change', ascending=False).head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>sat_part_rate_2017</th>
      <th>sat_total_2017</th>
      <th>sat_part_rate_2018</th>
      <th>sat_total_2018</th>
      <th>sat_part_rate_change</th>
      <th>act_part_rate_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13</th>
      <td>Illinois</td>
      <td>9</td>
      <td>1115</td>
      <td>99</td>
      <td>1019</td>
      <td>90</td>
      <td>-50</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Colorado</td>
      <td>11</td>
      <td>1201</td>
      <td>100</td>
      <td>1025</td>
      <td>89</td>
      <td>-70</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Rhode Island</td>
      <td>71</td>
      <td>1062</td>
      <td>97</td>
      <td>1018</td>
      <td>26</td>
      <td>-6</td>
    </tr>
    <tr>
      <th>48</th>
      <td>West Virginia</td>
      <td>14</td>
      <td>1086</td>
      <td>28</td>
      <td>999</td>
      <td>14</td>
      <td>-4</td>
    </tr>
    <tr>
      <th>30</th>
      <td>New Jersey</td>
      <td>70</td>
      <td>1056</td>
      <td>82</td>
      <td>1094</td>
      <td>12</td>
      <td>-3</td>
    </tr>
  </tbody>
</table>
</div>



## Conclusion & Recommendations

The participation rate in both test for each year (see scatterplot) reflect similar trend with states either preferring one over the other. Having said that, there seems to be no obvious preferrence of one over the other and changes in participation can likely result due to change in state's legislation or change of testing contractors. 

ACT and SAT scores are inversely correlated with their respective participation rates. In non-mandatory states, participants only parttake the test if they believe they are prepared and able to achieve a high score in the test. While in states where exam are mandatory, participants may be 'forced' to take the exam regardless if they have the abilit y to beat the average. 

SAT was more likely used by students living in coastal states and ACT was more widely used by students in the Midwest & South. Although there seem to be a shift in trend but the result as is could be due to regional and/or political affiliations associated with vendor of ACT or SAT.

SAT has seens increasing participation year-on-year as compared to ACT, which remains relative stable. Compared with ACT, SAT have gain more participation in 2018. This could be due to their initiatives to: 
1. Offer free SAT 'school day' event, where participants can take the exam during regular school day with the cost covered by their schools, not their parents. 
2. Partnering with other education providers to provide review lesson and practice tests.
    
Based on analysis of the data & additional research, I choose Florida as the next state we can invest in. The reason for choosing the state are as follow:

1. Florida is the 3rd largest state in term of population which means that there are likely to have more students participating in college admission test.

2. As an investment risk mitigation option, we may not be able to replicate the success case of Illinois & Colorado, low SAT to high SAT participation rate. Using Florida, which already have close to 50% participation rate in both SAT and ACT, it is likely to have less 'barrier to entry' for students to switch from ACT to SAT since they may be familiar with the structure of both exam.

3. Florida is committed to make big investment into education, hence it is highly likely to win political favor in expanding into Florida, given that our part of our current initiatives (free online review/classes) can contribute to more students being admitted to college.


College Board should continue with these initiatives for states which have a participation rate of 50% and above in 2018 going forward will most likely to see an increase in their popularity among the students. 

Supporting References: 
- <a herf="https://www.collegeraptor.com/getting-in/articles/act-sat/preference-act-sat-state-infographic/"> State Exam Preference</a>
- <a herf="https://archive.nytimes.com/www.nytimes.com/interactive/2013/08/04/education/edlife/where-the-sat-and-act-dominate.html">where SAT & ACT dominate</a>
- <a herf="https://en.wikipedia.org/wiki/SAT"> SAT Prefernce</a>
- <a herf="https://www.orlandosentinel.com/news/education/os-ne-act-sat-florida-scores-20181024-story.html">SAT Initiative in Florida</a>
- <a herf="https://www.politifact.com/factchecks/2017/may/15/richard-corcoran/corcoran-touts-level-education-spending-there/"> Florida make big investment in education</a>
